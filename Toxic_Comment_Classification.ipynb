{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>\n",
    "Toxic Comments Kaggle Competition Classifying\n",
    "</center></h1>\n",
    "<h2><center>\n",
    "Modeling the Data\n",
    "</center></h2>\n",
    "<h3><center>\n",
    "Marcel Colvin 912033961\n",
    "</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import time\n",
    "import re\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"training_data.csv\")\n",
    "test = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153164"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Classifier with w2v algorithm\n",
    "### This had 95.35% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"avg_word\"] = train[\"avg_word\"].apply(lambda x: \n",
    "                           np.fromstring(\n",
    "                               x.replace('\\n','')\n",
    "                                .replace('[','')\n",
    "                                .replace(']','')\n",
    "                                .replace('  ',' '), sep=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"avg_word\"] = test[\"avg_word\"].apply(lambda x: \n",
    "                           np.fromstring(\n",
    "                               x.replace('\\n','')\n",
    "                                .replace('[','')\n",
    "                                .replace(']','')\n",
    "                                .replace('  ',' '), sep=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = np.zeros((len(train),300), dtype=\"float64\")\n",
    "test_matrix = np.zeros((len(test),300), dtype=\"float64\")\n",
    "for i in range(len(train)):\n",
    "    train_matrix[i] = train.iloc[i][\"avg_word\"].reshape((1,300))\n",
    "for i in range(len(test)):\n",
    "        test_matrix[i] = test.iloc[i][\"avg_word\"].reshape((1,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [train[\"toxic\"], train[\"severe_toxic\"], train[\"obscene\"], train[\"threat\"], train[\"insult\"], train[\"identity_hate\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train[\"avg_word\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = []\n",
    "for i in range(6):\n",
    "    m = MLPClassifier(hidden_layer_sizes=(30,30,30), random_state=5)\n",
    "    model.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    model[i].partial_fit(train_matrix, y_train[i], [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test[['id']].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['toxic'] = model[0].predict_proba(test_matrix)[:,1]\n",
    "result['severe_toxic'] = model[1].predict_proba(test_matrix)[:,1]\n",
    "result['obscene'] = model[2].predict_proba(test_matrix)[:,1]\n",
    "result['threat'] = model[3].predict_proba(test_matrix)[:,1]\n",
    "result['insult'] = model[4].predict_proba(test_matrix)[:,1]\n",
    "result['identity_hate'] = model[5].predict_proba(test_matrix)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 95.09%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = []\n",
    "for i in range(6):\n",
    "    m = LogisticRegression(C=10.0)\n",
    "    model.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    model[i].fit(train_matrix, y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test[['id']].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['toxic'] = model[0].predict_proba(test_matrix)[:,1]\n",
    "result['severe_toxic'] = model[1].predict_proba(test_matrix)[:,1]\n",
    "result['obscene'] = model[2].predict_proba(test_matrix)[:,1]\n",
    "result['threat'] = model[3].predict_proba(test_matrix)[:,1]\n",
    "result['insult'] = model[4].predict_proba(test_matrix)[:,1]\n",
    "result['identity_hate'] = model[5].predict_proba(test_matrix)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF Logistitc Regression, \"comment_text\" uncleaned\n",
    "### This had 93.94% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvect = TfidfVectorizer(max_features=5000,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidfvect.fit_transform(train[\"comment_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = tfidfvect.transform(test[\"comment_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [train[\"toxic\"], train[\"severe_toxic\"], train[\"obscene\"], train[\"threat\"], train[\"insult\"], train[\"identity_hate\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = []\n",
    "for i in range(6):\n",
    "    m = LogisticRegression(C=10.0)\n",
    "    model.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    model[i].fit(X,y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test[['id']].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['toxic'] = model[0].predict_proba(testX)[:,1]\n",
    "result['severe_toxic'] = model[1].predict_proba(testX)[:,1]\n",
    "result['obscene'] = model[2].predict_proba(testX)[:,1]\n",
    "result['threat'] = model[3].predict_proba(testX)[:,1]\n",
    "result['insult'] = model[4].predict_proba(testX)[:,1]\n",
    "result['identity_hate'] = model[5].predict_proba(testX)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning \"comment_text\" to run TFIDF Logistic Regression Again\n",
    "### This had 96.30% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(word):\n",
    "    word = word.lower()\n",
    "    word = re.sub(r\"\\'s\", ' ', word)\n",
    "    word = re.sub(\"<[^>]*>\", \" \", word)\n",
    "    word = re.sub('\\W', ' ', word)\n",
    "    word = re.sub('\\s+', ' ', word)\n",
    "    word = word.strip(' ')\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"comment_text\"] = train['comment_text'].map(lambda word : text_cleaner(word))\n",
    "test[\"comment_text\"] = test['comment_text'].map(lambda word : text_cleaner(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvect = TfidfVectorizer(max_features=5000,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidfvect.fit_transform(train[\"comment_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [train[\"toxic\"], train[\"severe_toxic\"], train[\"obscene\"], train[\"threat\"], train[\"insult\"], train[\"identity_hate\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = tfidfvect.transform(test[\"comment_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = []\n",
    "for i in range(6):\n",
    "    m = LogisticRegression(C=10.0)\n",
    "    model.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-319cf6de5477>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fit() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    model[i].fit(X,y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test[['id']].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['toxic'] = model[0].predict_proba(testX)[:,1]\n",
    "result['severe_toxic'] = model[1].predict_proba(testX)[:,1]\n",
    "result['obscene'] = model[2].predict_proba(testX)[:,1]\n",
    "result['threat'] = model[3].predict_proba(testX)[:,1]\n",
    "result['insult'] = model[4].predict_proba(testX)[:,1]\n",
    "result['identity_hate'] = model[5].predict_proba(testX)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPClassifier Quick\n",
    "### 95.21% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = []\n",
    "for i in range(6):\n",
    "    m = MLPClassifier(hidden_layer_sizes=(30,30,30), random_state=5)\n",
    "    model.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    model[i].partial_fit(X,y_train[i], [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test[['id']].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['toxic'] = model[0].predict_proba(testX)[:,1]\n",
    "result['severe_toxic'] = model[1].predict_proba(testX)[:,1]\n",
    "result['obscene'] = model[2].predict_proba(testX)[:,1]\n",
    "result['threat'] = model[3].predict_proba(testX)[:,1]\n",
    "result['insult'] = model[4].predict_proba(testX)[:,1]\n",
    "result['identity_hate'] = model[5].predict_proba(testX)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HHH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/marcel/Github/Toxic_comments/nyt-comments/comments/CommentsMarch2018.csv\n",
      "/home/marcel/Github/Toxic_comments/nyt-comments/comments/CommentsApril2018.csv\n",
      "/home/marcel/Github/Toxic_comments/nyt-comments/comments/CommentsMarch2017.csv\n",
      "/home/marcel/Github/Toxic_comments/nyt-comments/comments/CommentsApril2017.csv\n",
      "/home/marcel/Github/Toxic_comments/nyt-comments/comments/CommentsJan2018.csv\n",
      "/home/marcel/Github/Toxic_comments/nyt-comments/comments/CommentsMay2017.csv\n",
      "/home/marcel/Github/Toxic_comments/nyt-comments/comments/CommentsJan2017.csv\n",
      "/home/marcel/Github/Toxic_comments/nyt-comments/comments/CommentsFeb2018.csv\n",
      "/home/marcel/Github/Toxic_comments/nyt-comments/comments/CommentsFeb2017.csv\n"
     ]
    }
   ],
   "source": [
    "path = '/home/marcel/Github/Toxic_comments/nyt-comments/comments/'\n",
    "nyt_comments = pd.DataFrame()\n",
    "for file_name in glob.glob(path+'*.csv'):\n",
    "    nyt_comments = nyt_comments.append(pd.read_csv(file_name)[['commentBody', 'commentID', \"reportAbuseFlag\", 'userLocation', 'userID']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_comments[\"commentBody\"] = nyt_comments['commentBody'].map(lambda word : text_cleaner(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_comments = nyt_comments.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nyt = tfidfvect.transform(nyt_comments[\"commentBody\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = nyt_comments[[\"commentID\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['toxic'] = model[0].predict_proba(test_nyt)[:,1]\n",
    "result['severe_toxic'] = model[1].predict_proba(test_nyt)[:,1]\n",
    "result['obscene'] = model[2].predict_proba(test_nyt)[:,1]\n",
    "result['threat'] = model[3].predict_proba(test_nyt)[:,1]\n",
    "result['insult'] = model[4].predict_proba(test_nyt)[:,1]\n",
    "result['identity_hate'] = model[5].predict_proba(test_nyt)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_nyt_coms = nyt_comments.loc[np.where(result['toxic'] > .8)][\"commentBody\"].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [None]*len(toxic_nyt_coms)\n",
    "for i in range(len(toxic_nyt_coms)):\n",
    "     x[i] = sid.polarity_scores(toxic_nyt_coms[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_comments = pd.DataFrame(toxic_nyt_coms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_comments[\"sent_anal\"] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_comments['neg'] = [d['neg'] for d in toxic_comments[\"sent_anal\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_comments['neu'] = [d['neu'] for d in toxic_comments[\"sent_anal\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_comments['pos'] = [d['pos'] for d in toxic_comments[\"sent_anal\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_comments['compound'] = [d['compound'] for d in toxic_comments[\"sent_anal\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24774395560840243"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(toxic_comments[\"neg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08740048694864437"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(toxic_comments[\"pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6648578789423044"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(toxic_comments[\"neu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5204957533548517"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(toxic_comments[\"compound\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [None]*len(nyt_comments)\n",
    "for i in range(len(nyt_comments)):\n",
    "     x[i] = sid.polarity_scores(nyt_comments.iloc[i][\"commentBody\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nyt_comments[\"sent_anal\"] = x\n",
    "nyt_comments['neg'] = [d['neg'] for d in x]\n",
    "nyt_comments['neu'] = [d['neu'] for d in x]\n",
    "nyt_comments['pos'] = [d['pos'] for d in x]\n",
    "nyt_comments['compound'] = [d['compound'] for d in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09928626093795935"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(nyt_comments[\"neg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11829671920689967"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(nyt_comments[\"pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.782388060085638"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(nyt_comments[\"neu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06153051704583903"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(nyt_comments[\"compound\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_comments.to_csv(\"nyt_commentsdf.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
